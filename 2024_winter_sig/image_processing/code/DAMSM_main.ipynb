{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from miscc.utils import mkdir_p\n",
    "from miscc.utils import build_super_images\n",
    "from miscc.losses import sent_loss, words_loss\n",
    "from miscc.config import cfg, cfg_from_file\n",
    "from DAMSM_train import train, evaluate, build_models, parse_args\n",
    "from datasets import TextDataset\n",
    "from datasets import prepare_data\n",
    "\n",
    "from model import RNN_ENCODER, CNN_ENCODER\n",
    "\n",
    "import os\n",
    "import sys\n",
    "# 파일 경로 조작 및 시스템 경로 설정\n",
    "import time\n",
    "# 코드 실행 시간을 측정\n",
    "import random\n",
    "# 난수 생성\n",
    "import pprint\n",
    "# 설정 파일을 예쁘게 출력하는 용도\n",
    "import datetime\n",
    "import dateutil.tz\n",
    "# 현재 시간과 타임스탬프를 관리\n",
    "import argparse\n",
    "import numpy as np\n",
    "# 배열 연산을 위해 사용\n",
    "from PIL import Image\n",
    "# 이미지 저장 및 변환\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# 기본적인 PyTorch 기능과 신경망 모듈\n",
    "import torch.optim as optim\n",
    "# 옵티마이저 관련 모듈\n",
    "from torch.autograd import Variable\n",
    "# 자동 미분 기능을 위한 래퍼 (PyTorch 최신 버전에서는 필요 X)\n",
    "import torch.backends.cudnn as cudnn\n",
    "# GPU 연산 최적화\n",
    "import torchvision.transforms as transforms\n",
    "# 이미지 전처리(transform) 관련 기능 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\blues\\바탕 화면\\혜원\\개인공부\\SIG\\2024-SIG\\2024_winter_sig\\image_processing\\code\n"
     ]
    }
   ],
   "source": [
    "dir_path = os.path.abspath(os.path.join(os.getcwd(), './.'))\n",
    "# .../image_processing/code\n",
    "sys.path.append(dir_path)\n",
    "\n",
    "print(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cfg_file='cfg/DAMSM/coco.yml', gpu_id=1, data_dir='', manualSeed=None)\n"
     ]
    }
   ],
   "source": [
    "sys.argv = ['pretrain_DAMSM.py', '--cfg', 'cfg/DAMSM/coco.yml', '--gpu', '1']\n",
    "args = parse_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using config:\n",
      "{'B_VALIDATION': False,\n",
      " 'CONFIG_NAME': 'DAMSM',\n",
      " 'CUDA': True,\n",
      " 'DATASET_NAME': 'coco',\n",
      " 'DATA_DIR': '../data/coco',\n",
      " 'GAN': {'B_ATTENTION': True,\n",
      "         'B_DCGAN': False,\n",
      "         'CONDITION_DIM': 100,\n",
      "         'DF_DIM': 64,\n",
      "         'GF_DIM': 128,\n",
      "         'R_NUM': 2,\n",
      "         'Z_DIM': 100},\n",
      " 'GPU_ID': 1,\n",
      " 'RNN_TYPE': 'LSTM',\n",
      " 'TEXT': {'CAPTIONS_PER_IMAGE': 5, 'EMBEDDING_DIM': 256, 'WORDS_NUM': 15},\n",
      " 'TRAIN': {'BATCH_SIZE': 48,\n",
      "           'B_NET_D': True,\n",
      "           'DISCRIMINATOR_LR': 0.0002,\n",
      "           'ENCODER_LR': 0.002,\n",
      "           'FLAG': True,\n",
      "           'GENERATOR_LR': 0.0002,\n",
      "           'MAX_EPOCH': 600,\n",
      "           'NET_E': '',\n",
      "           'NET_G': '',\n",
      "           'RNN_GRAD_CLIP': 0.25,\n",
      "           'SMOOTH': {'GAMMA1': 4.0,\n",
      "                      'GAMMA2': 5.0,\n",
      "                      'GAMMA3': 10.0,\n",
      "                      'LAMBDA': 1.0},\n",
      "           'SNAPSHOT_INTERVAL': 5},\n",
      " 'TREE': {'BASE_SIZE': 299, 'BRANCH_NUM': 1},\n",
      " 'WORKERS': 1}\n"
     ]
    }
   ],
   "source": [
    "if args.cfg_file is not None:\n",
    "     cfg_from_file(args.cfg_file)\n",
    "\n",
    "if args.gpu_id == -1:\n",
    "    cfg.CUDA = False\n",
    "else:\n",
    "    cfg.GPU_ID = args.gpu_id\n",
    "\n",
    "if args.data_dir != '':\n",
    "    cfg.DATA_DIR = args.data_dir\n",
    "print('Using config:')\n",
    "pprint.pprint(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manualSeed: 3340\n",
      "Updated manualSeed: 3340\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('manualSeed:', args.manualSeed)  # manualSeed 값 출력\n",
    "if not cfg.TRAIN.FLAG:\n",
    "    args.manualSeed = 100\n",
    "elif args.manualSeed is None:\n",
    "    args.manualSeed = random.randint(1, 10000)\n",
    "    \n",
    "print('Updated manualSeed:', args.manualSeed)\n",
    "random.seed(args.manualSeed)\n",
    "np.random.seed(args.manualSeed)\n",
    "torch.manual_seed(args.manualSeed)\n",
    "if cfg.CUDA:\n",
    "    torch.cuda.manual_seed_all(args.manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now(dateutil.tz.tzlocal())\n",
    "timestamp = now.strftime('%Y_%m_%d_%H_%M_%S')\n",
    "# 현재 시간과 시스템의 로컬 타임존 정보를 가져옴\n",
    "\n",
    "output_dir = '../output/%s_%s_%s' % \\\n",
    "    (cfg.DATASET_NAME, cfg.CONFIG_NAME, timestamp)\n",
    "# 디렉토리 경로 생성\n",
    "\n",
    "model_dir = os.path.join(output_dir, 'Model')\n",
    "image_dir = os.path.join(output_dir, 'Image')\n",
    "# 모델과 이미지 저장용 디렉토리 경로 설정\n",
    "mkdir_p(model_dir)\n",
    "# mkdir_p : 지정된 디렉토리가 존재하지 않으면 생성하는 함수수\n",
    "mkdir_p(image_dir)\n",
    "\n",
    "torch.cuda.set_device(cfg.GPU_ID)\n",
    "# 저장된 GPU ID로 GPU를 설정한다.\n",
    "cudnn.benchmark = True\n",
    "# cuDNN의 최적화 활성화화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = cfg.TREE.BASE_SIZE * (2 ** (cfg.TREE.BRANCH_NUM-1))\n",
    "# 입력 이미지의 크기를 결정\n",
    "batch_size = cfg.TRAIN.BATCH_SIZE\n",
    "\n",
    "## 이미지 전처리\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Scale(int(imsize * 76 / 64)),\n",
    "    transforms.RandomCrop(imsize),\n",
    "    transforms.RandomHorizontalFlip()])\n",
    "\n",
    "#### train dataset Load\n",
    "dataset = TextDataset(cfg.DATA_DIR, 'train',\n",
    "                          base_size=cfg.TREE.BASE_SIZE,\n",
    "                          transform=image_transform)\n",
    "print(dataset.n_words, dataset.embeddings_num)\n",
    "\"\"\"\n",
    "dataset.nwords : 데이터 셋의 단어 수\n",
    "dataset.embeddings_num : 임베딩 크기 \n",
    "\"\"\"\n",
    "\n",
    "assert dataset, \"Invalid Dataset\"\n",
    "# PyThon에서 단순한 존재 검증 즉, True로 평가되는 값인지 확인\n",
    "# None 값, 빈 리스트, 빈 문자열, 0, False 같은 값이면 AssertionError 발생\n",
    "\n",
    "# DataLoader : PyTorch에서 데이터를 배치 단위로 처리하기 위한 도구구\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, drop_last=True,\n",
    "    shuffle=True, num_workers=int(cfg.WORKERS))\n",
    "# drop_last=True : 데이터셋의 크기가 배치 크기로 나누어떨어지지 않는 경우 마지막 배치를 버린다.\n",
    "\n",
    "#### validation dataset Load\n",
    "dataset_val = TextDataset(cfg.DATA_DIR, 'test',\n",
    "                        base_size=cfg.TREE.BASE_SIZE,\n",
    "                        transform=image_transform)\n",
    "print(dataset.n_words, dataset.embeddings_num)\n",
    "\n",
    "dataloader_val = torch.utils.data.DataLoader(\n",
    "    dataset_val, batch_size=batch_size, drop_last=True,\n",
    "    shuffle=True, num_workers=int(cfg.WORKERS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoder, image_encoder, labels, start_epoch = build_models()\n",
    "para = list(text_encoder.parameters())\n",
    "for v in image_encoder.parameters():\n",
    "    if v.requires_grad:\n",
    "        para.append(v)\n",
    "# optimizer = optim.Adam(para, lr=cfg.TRAIN.ENCODER_LR, betas=(0.5, 0.999))\n",
    "# At any point you can hit Ctrl + C to break out of training early.\n",
    "try:\n",
    "    lr = cfg.TRAIN.ENCODER_LR\n",
    "    for epoch in range(start_epoch, cfg.TRAIN.MAX_EPOCH):\n",
    "        optimizer = optim.Adam(para, lr=lr, betas=(0.5, 0.999))\n",
    "        epoch_start_time = time.time()\n",
    "        count = train(dataloader, image_encoder, text_encoder,\n",
    "                    batch_size, labels, optimizer, epoch,\n",
    "                    dataset.ixtoword, image_dir)\n",
    "        print('-' * 89)\n",
    "        if len(dataloader_val) > 0:\n",
    "            s_loss, w_loss = evaluate(dataloader_val, image_encoder,\n",
    "                                      text_encoder, batch_size)\n",
    "            print('| end epoch {:3d} | valid loss '\n",
    "                  '{:5.2f} {:5.2f} | lr {:.5f}|'\n",
    "                  .format(epoch, s_loss, w_loss, lr))\n",
    "        print('-' * 89)\n",
    "        if lr > cfg.TRAIN.ENCODER_LR/10.:\n",
    "            lr *= 0.98\n",
    "\n",
    "        if (epoch % cfg.TRAIN.SNAPSHOT_INTERVAL == 0 or\n",
    "            epoch == cfg.TRAIN.MAX_EPOCH):\n",
    "            torch.save(image_encoder.state_dict(),\n",
    "                       '%s/image_encoder%d.pth' % (model_dir, epoch))\n",
    "            torch.save(text_encoder.state_dict(),\n",
    "                       '%s/text_encoder%d.pth' % (model_dir, epoch))\n",
    "            print('Save G/Ds models.')\n",
    "except KeyboardInterrupt:\n",
    "    print('-' * 89)\n",
    "    print('Exiting from training early')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2024WINTERSIG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
